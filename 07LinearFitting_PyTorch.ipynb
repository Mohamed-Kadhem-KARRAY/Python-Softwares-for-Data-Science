{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eb25b07",
   "metadata": {},
   "source": [
    "# Linear fitting using a neural network with PyTorch\n",
    "### Author : Mohamed Kadhem KARRAY \n",
    "\n",
    "- Website: https://mohamedkadhem.com\n",
    "- Youtube: https://www.youtube.com/@mohamedkadhemkarray2504\n",
    "- LinkedIn: https://www.linkedin.com/in/mohamed-kadhem-karray-b21895b\n",
    "\n",
    "### Date: 2023 september 15th\n",
    "### Content\n",
    "- In this example, from [1], we shall make a linear fitting between the input x and the output y in the form y=wx+b, using a neural network and the Pytorch package.\n",
    ". Observe that we obtain the same result as in Example 2 \"Linear fitting using sklearn package\" [2]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a667879",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23ecba0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\applications\\python\\python311\\lib\\site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in c:\\applications\\python\\python311\\lib\\site-packages (from torch) (3.12.3)\n",
      "Requirement already satisfied: typing-extensions in c:\\applications\\python\\python311\\lib\\site-packages (from torch) (4.7.1)\n",
      "Requirement already satisfied: sympy in c:\\applications\\python\\python311\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\applications\\python\\python311\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\applications\\python\\python311\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\applications\\python\\python311\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\applications\\python\\python311\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "# Installing package using \"pip\" command.\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d932a12",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14125a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee28030",
   "metadata": {},
   "source": [
    "## Linear fitting using a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efbd241b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 , loss= 477.0\n",
      "Iteration 1 , loss= 31.6619873046875\n",
      "Iteration 2 , loss= 16.4942684173584\n",
      "Iteration 3 , loss= 15.976585388183594\n",
      "Iteration 4 , loss= 15.957910537719727\n",
      "Iteration 5 , loss= 15.956314086914062\n",
      "Iteration 6 , loss= 15.955360412597656\n",
      "Iteration 7 , loss= 15.954484939575195\n",
      "Iteration 8 , loss= 15.95367431640625\n",
      "Iteration 9 , loss= 15.952923774719238\n",
      "Iteration 10 , loss= 15.952216148376465\n",
      "Iteration 11 , loss= 15.95156192779541\n",
      "Iteration 12 , loss= 15.95095443725586\n",
      "Iteration 13 , loss= 15.950397491455078\n",
      "Iteration 14 , loss= 15.949872970581055\n",
      "Iteration 15 , loss= 15.949380874633789\n",
      "Iteration 16 , loss= 15.948927879333496\n",
      "Iteration 17 , loss= 15.948501586914062\n",
      "Iteration 18 , loss= 15.948111534118652\n",
      "Iteration 19 , loss= 15.947741508483887\n",
      "Iteration 20 , loss= 15.947402954101562\n",
      "Iteration 21 , loss= 15.947092056274414\n",
      "Iteration 22 , loss= 15.946796417236328\n",
      "Iteration 23 , loss= 15.946516036987305\n",
      "Iteration 24 , loss= 15.946268081665039\n",
      "Iteration 25 , loss= 15.94603157043457\n",
      "Iteration 26 , loss= 15.945812225341797\n",
      "Iteration 27 , loss= 15.945598602294922\n",
      "Iteration 28 , loss= 15.945411682128906\n",
      "Iteration 29 , loss= 15.94522476196289\n",
      "Iteration 30 , loss= 15.945072174072266\n",
      "Iteration 31 , loss= 15.944912910461426\n",
      "Iteration 32 , loss= 15.944771766662598\n",
      "Iteration 33 , loss= 15.944631576538086\n",
      "Iteration 34 , loss= 15.944517135620117\n",
      "Iteration 35 , loss= 15.944391250610352\n",
      "Iteration 36 , loss= 15.944293975830078\n",
      "Iteration 37 , loss= 15.94418716430664\n",
      "Iteration 38 , loss= 15.944095611572266\n",
      "Iteration 39 , loss= 15.944012641906738\n",
      "Iteration 40 , loss= 15.943927764892578\n",
      "Iteration 41 , loss= 15.943853378295898\n",
      "Iteration 42 , loss= 15.943780899047852\n",
      "Iteration 43 , loss= 15.943719863891602\n",
      "Iteration 44 , loss= 15.943659782409668\n",
      "Iteration 45 , loss= 15.943605422973633\n",
      "Iteration 46 , loss= 15.94355583190918\n",
      "Iteration 47 , loss= 15.943501472473145\n",
      "Iteration 48 , loss= 15.943462371826172\n",
      "Iteration 49 , loss= 15.9434232711792\n",
      "Iteration 50 , loss= 15.943380355834961\n",
      "Iteration 51 , loss= 15.94334602355957\n",
      "Iteration 52 , loss= 15.943302154541016\n",
      "Iteration 53 , loss= 15.94327163696289\n",
      "Iteration 54 , loss= 15.943243980407715\n",
      "Iteration 55 , loss= 15.943212509155273\n",
      "Iteration 56 , loss= 15.94320297241211\n",
      "Iteration 57 , loss= 15.943178176879883\n",
      "Iteration 58 , loss= 15.943145751953125\n",
      "Iteration 59 , loss= 15.943124771118164\n",
      "Iteration 60 , loss= 15.943109512329102\n",
      "Iteration 61 , loss= 15.943087577819824\n",
      "Iteration 62 , loss= 15.943071365356445\n",
      "Iteration 63 , loss= 15.94306755065918\n",
      "Iteration 64 , loss= 15.943053245544434\n",
      "Iteration 65 , loss= 15.943031311035156\n",
      "Iteration 66 , loss= 15.943023681640625\n",
      "Iteration 67 , loss= 15.943009376525879\n",
      "Iteration 68 , loss= 15.942996978759766\n",
      "Iteration 69 , loss= 15.942991256713867\n",
      "Iteration 70 , loss= 15.942981719970703\n",
      "Iteration 71 , loss= 15.942973136901855\n",
      "Iteration 72 , loss= 15.942964553833008\n",
      "Iteration 73 , loss= 15.942955017089844\n",
      "Iteration 74 , loss= 15.942947387695312\n",
      "Iteration 75 , loss= 15.94294548034668\n",
      "Iteration 76 , loss= 15.942939758300781\n",
      "Iteration 77 , loss= 15.94293212890625\n",
      "Iteration 78 , loss= 15.942926406860352\n",
      "Iteration 79 , loss= 15.942919731140137\n",
      "Iteration 80 , loss= 15.94291877746582\n",
      "Iteration 81 , loss= 15.942911148071289\n",
      "Iteration 82 , loss= 15.942907333374023\n",
      "Iteration 83 , loss= 15.942901611328125\n",
      "Iteration 84 , loss= 15.942903518676758\n",
      "Iteration 85 , loss= 15.942900657653809\n",
      "Iteration 86 , loss= 15.942899703979492\n",
      "Iteration 87 , loss= 15.942892074584961\n",
      "Iteration 88 , loss= 15.942888259887695\n",
      "Iteration 89 , loss= 15.942895889282227\n",
      "Iteration 90 , loss= 15.94288444519043\n",
      "Iteration 91 , loss= 15.942876815795898\n",
      "Iteration 92 , loss= 15.94288158416748\n",
      "Iteration 93 , loss= 15.94288158416748\n",
      "Iteration 94 , loss= 15.942885398864746\n",
      "Iteration 95 , loss= 15.942880630493164\n",
      "Iteration 96 , loss= 15.942872047424316\n",
      "Iteration 97 , loss= 15.94287109375\n",
      "Iteration 98 , loss= 15.942865371704102\n",
      "Iteration 99 , loss= 15.942879676818848\n",
      "Parameters after training:\n",
      "Parameter containing:\n",
      "tensor([[3.6579]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([1.8544], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x=np.array([[0],[1],[2],[3],[4],[5]])\n",
    "y=np.array([[1],[7],[8],[15],[14],[21]])\n",
    "dtype=torch.FloatTensor\n",
    "x=torch.from_numpy(x).type(dtype)\n",
    "y=torch.from_numpy(y).type(dtype)\n",
    "\n",
    "# Initial values of parameters\n",
    "w=torch.from_numpy(np.array([[1.0]])).type(dtype)\n",
    "b=torch.from_numpy(np.array([1.0])).type(dtype)\n",
    "learning_rate = 1e-2\n",
    "\n",
    "# Neural network with unidimensional input and output\n",
    "net=torch.nn.Sequential(torch.nn.Linear(1,1))\n",
    "for m in net.children():\n",
    "    m.weight.data=w.clone()\n",
    "    m.bias.data=b.clone()\n",
    "loss_fn=torch.nn.MSELoss(reduction='sum') # Least-squares fitting\n",
    "optimizer=torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "for epoch in range(100):\n",
    "    yt=net(x)\n",
    "    loss=loss_fn(yt,y)\n",
    "    print(\"Iteration\", epoch, \", loss=\",loss.item())\n",
    "    optimizer.zero_grad() # clear gradients for next train\n",
    "    loss.backward() # compute gradients by back propagation\n",
    "    optimizer.step() # update the parameters by applying gradients\n",
    "print(\"Parameters after training:\")\n",
    "for param in net.parameters():\n",
    "    print(param)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da1fd8b",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] M. Lelarge et al., https://dataflowr.github.io/website\n",
    "\n",
    "[2] Example 2 \"Linear fitting using sklearn package\",  https://github.com/Mohamed-Kadhem-KARRAY/Python-Softwares-for-Data-Science/blob/81cc7091402ad999e74837ec16444251028d03d8/02LinearFitting_sklearn.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
